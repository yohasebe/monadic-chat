- [August 23, 2025] Latest Updates
  - **Comprehensive Language Selector**: Unified language control for UI and AI
    - Moved language selector from settings panel to info panel for better visibility
    - Single selector controls STT, TTS, and AI response language
    - 57 languages supported with native names display (e.g., "日本語 (Japanese)")
    - Language preference automatically injected into system prompts
    - Proper "auto" handling to prevent API errors
    - Works seamlessly with initiate_from_assistant mode
    - All WebSocket messages now carry interface_language parameter

- [August 22, 2025] Recent Updates
  - **Unified Error Formatting System**: Consistent error messages across all providers
    - Implemented centralized error formatter for all 8 AI providers
    - Standardized format: `[Provider] Category: Message (Code: XXX) Suggestion: Action`
    - User-friendly suggestions for common issues (e.g., API key setup instructions)
    - Categories: API Key Error, API Error, Network Error, Parsing Error, Tool Execution Error
    - Clear provider identification in all error messages
  - **DeepSeek Strict Function Calling**: Beta API integration for improved reliability
    - Automatic schema conversion with ALL properties in required arrays
    - Special marker filtering (`<｜tool▁call▁end｜>`) from streaming responses
    - Enabled by default for deepseek-chat model
    - Significantly improves Code Interpreter parameter parsing
    - 12 comprehensive tests for schema conversion logic
  - **Cohere Reasoning Model**: Added command-a-reasoning-08-2025
    - 256K context window, 32K output capacity
    - Known limitation: Error 422 with thinking + assistant messages
    - Enhanced debugging for API request/response analysis
    - 9 tests for conversation formatting workarounds

- [August 16, 2025] Previous Updates
  - **Monadic Mode Investigation**: Comprehensive testing of Claude's compatibility
    - Confirmed fundamental incompatibility between Claude's thinking mode and JSON structure
    - Claude, Gemini, and Grok require `monadic: false` for tool-heavy applications
    - Only OpenAI successfully combines monadic mode with extensive tool usage
    - Documented technical limitations and future considerations
  - **Jupyter Notebook Configuration**: Optimized provider-specific settings
    - Reverted Claude to `monadic: false` for stable tool execution
    - Fixed context formatting issues from workload management changes
    - Corrected font configurations to use pre-installed Noto Sans CJK JP
  - **Documentation Enhancements**: Updated technical and user documentation
    - Added provider compatibility matrix for monadic mode + tools
    - Documented Claude's specific limitations with thinking blocks
    - Enhanced both English and Japanese docsify documentation

- [August 14-15, 2025] 1.0.0-beta.4
  - Version updated from 1.0.0-beta.2
  - **Claude Performance Optimizations**: Improved tool calling efficiency
    - Implemented batch processing for multiple tool calls in single API request
    - Set `reasoning_effort: minimal` for all Claude Sonnet 4 function-calling apps
    - Fixed minimum thinking_budget_tokens (1024) requirement for minimal mode
    - Significantly improved Jupyter Notebook cell addition performance
  - **Workload Management Feature**: Improved user control over batch vs step-by-step execution
    - Initial greeting now mentions batch processing option for efficiency
    - Users can request step-by-step execution at any time
    - Default is batch processing for efficiency
    - Automatically notifies for very large tasks (>20 cells for Jupyter, >5 executions for Code Interpreter)
  - **Matplotlib Best Practices**: Added guidance to prevent common plotting errors
    - Japanese fonts (Noto Sans CJK JP) pre-configured in containers
    - Fixed incorrect font specifications in Jupyter Notebook prompts
    - LaTeX annotation syntax corrections
    - Deprecated function updates (get_cmap, seaborn styles)
    - Prevents mixing LaTeX with non-ASCII text in annotations
  - **Math Tutor Consolidation**: Unified implementation across all providers
    - Created shared `math_tutor_constants.rb` module with common prompts and settings
    - All Math Tutor MDSL files now reference shared constants
    - Reduces duplication from 4 x 144 lines to 1 x 150 lines of shared code
    - DSL loader enhanced to auto-load `*_constants.rb` files alongside tools
  - **Unified Error Handling System**: Consistent error messages across all providers
    - Standardized format: `Error: [Category] - Message. Suggestion (Code: XXX)`
    - Smart error categorization with actionable suggestions
    - Progressive migration starting with Jupyter and Grok helpers
  - **MathJax Enhancement**: Fixed math rendering in header tags
    - Modified configuration to process h1-h6 tags
    - Added best practices to Math Tutor prompts
  - **Grok Jupyter Notebook**: Resolved filename timestamp issues
    - Implemented post-processing workaround for Grok's API limitations
    - Ensures users always see correct notebook filenames
  - **Math Tutor Expansion**: Added support for Claude, Gemini, and Grok
    - Previously OpenAI-only, now available for all major providers
  - **Testing Infrastructure**: Expanded to 1253 comprehensive tests
    - Enhanced test reliability with real implementation tests
    - Improved coverage across all components
  - **Gemini 2.5 Function Calling**: Fixed function calling with reasoning_effort parameter
    - Discovered fundamental trade-off: Cannot have both function calling and structured JSON output
    - Function calling requires `reasoning_effort: minimal` for Gemini 2.5 models
    - Structured output (monadic mode) requires NO reasoning_effort parameter
    - Migrated most apps to gemini-2.5-flash for better cost/performance ratio
    - Separated info-gathering tools from action tools to prevent exhausting tool call limits
  - **Jupyter Notebook**: Added Gemini and Grok support
    - Full function calling support for Jupyter operations
    - Natural language responses with embedded notebook links
    - Optimized for each provider's capabilities
  - **GPT-5 Models**: Full implementation for OpenAI GPT-5 series
    - gpt-5, gpt-5-mini, gpt-5-nano with 400K context window
    - 128K max output tokens and reasoning token support
    - Uses Responses API for enhanced tool handling and structured outputs
    - Supports "minimal" reasoning effort for optimal performance
    - Model fallback mechanism: Primary GPT-5, fallback to GPT-4.1
    - Proper structured output via text.format with JSON Schema (not response_format)
    - Fixed tool continuation and function_call format requirements
    - Documentation updated in English and Japanese for GPT-5 specifics
  - **GPT-5 Verbosity Support**: Added configurable output length control
    - New `verbosity` parameter in MDSL files: "high", "medium", or "low"
    - Works with both Chat Completions and Responses API
    - Optimizes latency by controlling output token generation
  - **Performance Improvements**:
    - Fixed "This may take a while" message to only show for truly slow models (o3, o3-pro)
    - Added timeout handling with user-friendly error messages
    - Default 120 seconds timeout for commands, configurable per operation
  - **Syntax Tree App Enhancements**:
    - Improved binary branching enforcement with stronger prompts
    - Better error handling for LaTeX/SVG generation
    - Removed language-specific examples for universal applicability
  - **Testing Infrastructure**:
    - Replaced mock-based tests with actual implementation tests
    - More reliable test coverage catching real integration issues
    - Test suite: 1253 examples, 0 failures
  - **Monadic Apps Fix**: Fixed context display for all monadic apps using GPT-5
    - Language Practice Plus, Chat Plus, and others now properly show context in UI
    - Fixed both Chat Completions and Responses API handlers
    - Added type safety for Hash, String, and other response types
  - **GPT-5 Token Limits**: Set appropriate defaults based on official specs
    - All GPT-5 variants: 128K max output tokens (400K context window)
    - Automatic fallback to model defaults when not specified in MDSL

- [June, 2025] 1.0.0-beta.2
  - **Security**: Path traversal protection for file operations
    - Validates file paths are within allowed directories
    - Prevents symlink-based attacks with `File.realpath`
    - Proper shell escaping for command execution
  - **Bug Fixes**: Provider-specific issues resolved
    - OpenAI Responses API: Fixed hash initialization for tool calls
    - Gemini: Fixed tool response role (user vs model)
    - DeepSeek: Added support for text-based function calls
  - **Gemini Native Search**: Google Gemini now uses native search API
    - No additional API key required for web search with Gemini
  - **Gemini Model Updates**: Standardized default models across all Gemini apps
    - Code execution apps: `gemini-2.5-pro` (Code Interpreter, Coding Assistant, Research Assistant)
    - Other apps: `gemini-2.5-flash`
  - **Test Infrastructure**: Major improvements to test stability and organization
    - Consolidated duplicate tests and improved naming consistency
    - Relaxed timeouts and expectations for better reliability
    - Fixed parameter passing issues for Claude and other providers
  - **Documentation**: Updated provider documentation to reflect native search capabilities

- [June, 2025] 1.0.0-beta.1
  - **Beta Release**: First beta release for version 1.0.0
  - **Important Changes**: See [documentation](https://yohasebe.github.io/monadic-chat/#/developer/breaking-changes) for migration guide
  - **New Apps**: Concept Visualizer (LaTeX/TikZ diagrams), Syntax Tree (linguistic analysis)
  - **Ollama Support**: Local LLM integration with automatic model management
  - **O3 Series Support**: OpenAI o3 and o3-pro models (o3-pro uses responses API)
  - **AI-Driven Web Search**: Replaced heuristic detection with AI-driven approach
    - AI models now decide when to use web search based on context
    - Chat apps: Web search disabled by default
    - Research Assistant apps: Web search enabled by default
    - OpenAI: Uses responses API with native web_search_preview tool for gpt-4.1/gpt-4.1-mini
    - Configuration option to force Tavily: `USE_TAVILY_FOR_OPENAI=true`
    - Fixed Responses API content type issue (tool messages excluded from input)
  - **Performance**: Faster command execution, improved audio processing
  - **UI Improvements**: Provider colors, API key warnings, model switch notifications

- [May, 2025] 0.9.982
  - Improved text-to-speech with OpenAI, Elevenlabs, and Google Gemini models
  - OpenAI and Anthropic models support native web search
  - xAI Grok models now support native web search via Live Search API
  - Update mechanism changed to manual download only (no automatic updates)
- [May, 2025] 0.9.93
  - Web Speech API (macOS and Windows) support for text-to-speech
  - Image generation app updated to support gpt-image-1 with image editing
  - Issues with copy-to-clipboard built-in browser for macOS fixed
  - Issues with text-to-speech and speech-to-text in built-in browser fixed
  - Code Interpreter app support for xAI Grok models added 
- [April, 2025] 0.9.85
  - Built-in browser introduced for web UI
  - Server mode (distributed mode) support added: Allows multiple clients
  - Better MathJax rendering
  - Asset inclusion issue fixed
  - Small UI modifications
- [April, 2025] 0.9.83
  - Better Markdown rendering with CommonMark support
  - Improved new version notification and update process
  - Added environment variables for configuring default models for each provider (OPENAI_DEFAULT_MODEL, ANTHROPIC_DEFAULT_MODEL, etc.)
  - Enhanced Monadic DSL to support default model configuration from environment variables
  - AI User feature significantly improved
  - Optimized container rebuilding process: Only rebuilds affected containers during version updates
  - Added container version tracking to avoid unnecessary full rebuilds
  - Reset button behavior change to preserve current app selection
  - Improved card UI and visual styling for message display, code blocks, and syntax highlighting
  - Many UI improvements and bug fixes (role selection, message editing, etc.)
  - TTS replacement dictionary feature availability and stability improvements 
- [March, 2025] 0.9.76
  - Added testing infrastructure for both Ruby (RSpec) and JavaScript (Jest) code with initial test suites
  - Changed project license from MIT to Apache License 2.0
  - Default syntax highlighting theme changed to pastie for better readability
  - Fixed display issues with code blocks in dark themes
  - Improved message editing: last message now moves to input area with role selected
  - Simplified message deletion with clearer options ("Delete this message and below")
  - Fixed copy functionality to avoid CSS artifacts
  - TTS related bug fixes
  - Two ways to delete a message: "Delete this message and below" and "Delete this message only"
  - Perplexity apps support "initiate_from_assistant"
  - Voice Chat/Mail Composer/Language Practice apps support multiple model providers
  - Mistral model handling issue fixed
  - Add support for new OpenAI speech-to-text models (gpt-4o-mini-transcribe, gpt-4o-transcribe)
  - Update audio format handling for optimal compatibility with different STT models
  - Add STT_MODEL selection in settings
  - OpenAI models and Google Gemini models support PDF input
  - DrawIO Grapher app added
  - Image generation app added for Google Gemini (Imagen)
  - OpenAI's web search feature supported
  - gpt-4o-(mini-)search-preview models supported
  - Cohere Command A models supported
  - CommandRHelper module renamed to CohereHelper (vendor-neutral naming)
  - User defined containers building process changed
  - Fix ElevenLabs TTS provider cookie persistence and auto-selection
  - Many small app improvements
  - Segmented tts playback feature restored
  - Basic architecture documentation updated
  - Add image support for Mistral models
  - Monadic DSL system introduced
  - App selection behavior made consistent for startup and reset
  - Setup script management improved
  - Fixed hardcoded local paths in help system scripts
  - Fixed undefined COMPOSE_FILES variable in build command
  - Fixed Docker Compose execution in packaged Electron apps with paths containing spaces
  - Added proper quoting for Docker commands to handle installation paths with spaces
  - Improved path handling in monadic.sh for production environments
- [February, 2025] 0.9.58
  - Declarative DSL for app authoring with documentation
  - IconHelper utility for simplified app icon management
  - `sysinfo` command added to Python container
  - Performance improvement and bug fixes
  - Extra logging feature added
  - Fixed Linux packaged app startup issues with missing setup script files
  - OpenAI `gpt-4.5-preview` model supported
  - Research Assistant app improved
  - Tavily web search and webpage extraction supported
  - ElevenLabs TTS voices supported
  - OpenAI o3-mini model supported with the `reasoning-effort` parameter
  - Jupyter Notebook apps improved with `jupyter.log` generated for each session
  - Perplexity `sonar-reasoning-pro` (DeepSeek R1) model supported
  - Math rendering option added to the web UI
  - Initial system prompt duplication issue fixed
  - TTS/STT support for Safari
  - Selenium image supported for both arm64 and amd64
- [Jan, 2025] 0.9.37
  - Perplexity `sonar-reasoning` (DeepSeek) model supported
  - OpenAI o1 models supported
  - DeepSeek models supported
  - Better logging for tool use (function calling)
  - New folder structure for config/data/logs introduced
  - Perplexity models supported
  - Start-up time (after build) improved
  - Perplexity `sonar-reasoning` (DeepSeek) model supported
  - OpenAI o1 models supported
  - DeepSeek models supported
  - Better logging for tool use (function calling)
  - New folder structure for config/data/logs introduced
  - Perplexity models supported
  - Start-up time (after build) improved
- [Dec, 2024] 0.9.30
  - "From URL" feature added
  - "From file" feature added (pdf, docx, pptx, xlsx, etc.)
  - xAI Grok models supported
  - Cohere API update to v2
  - Markdown rendering improved
  - Math Tutor app supports visualizations
  - Not require OpenAI's API token when using other APIs
  - Image generation feature improved
  - Many UI and under-the-hood improvements
  - User container rebuild feature fixed
  - Role selection issue fixed
- [Nov, 2024] 0.9.22
  - Rebuilding specific containers feature added
  - `pysetup.sh` extra installation script supported
  - Jupyter Notebook apps (for GPT and Claude) improved
  - Streaming supported for OpenAI's o1 models
  - CJK font issue on code apps addressed
  - Syntax highlighting theme option added
  - App settings convention enhanced with "group" attribute
  - Check for updates when starting the app
  - [Predicted output](https://platform.openai.com/docs/guides/latency-optimization#use-predicted-outputs) feature added for OpenAI's models
  - [PDF recognition](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support) feature added for Claude Sonnet models
  - AI user feature improved
- [Oct, 2024] 0.9.6
  - PyMuPDF4LLM integration
  - Anthropic's new sonnet model supported
  - Stability of code running and chart generation improved
- [Sep, 2024] 0.9.2
  - Beta models (`o1-preview`, `o1-mini`) supported
  - Documentation renewed
  - Stability improvement
  - Better app development support
  - Many under-the-hood improvements
  - Documentation using Docsify released
- [Aug, 2024] 0.8.11
  - App authoring format changed
  - Claude Jupyter Notebook app added
  - Math rendering improved
  - Second Opinion app added
  - PDF Document import/export feature
- [Jul, 2024] 
  - Mistral AI (Chat and Code Interpreter) app added
  - Multiple images can be uploaded for image recognition
  - Continue button introduced
  - Jupyter Notebook app added
  - Browser auto open
- [Jun, 2024] 
  - Linux (Ubuntu/Debian) installer released
  - App file name changed from monadic-chat to Monadic Chat
  - Settings menu added
  - Speech Draft Helper app added (with TTS audio file generation)
  - Menu bar items added; Shared Folder asccessible on Windows
  - Better uninstallation of containers
  - Monadic Chat Console UI improved
  - AI-User feature introduced
  - Automatic Docker image rebuild feature
  - Source code block copy button added
  - Video Describer app added
- [May, 2024] Talk to Claude/Cohere/Gemini apps added
  - Ruby/Python/PGVector/Selenium containers structure introduced
- [Feb, 2024] Mermaid diagram support
  - File reading feature
  - Stability improvement with several apps modified
- [Jan, 2024] Default model set to `gpt-3.5-turbo-1106`
  - OpenAI's January 2024 models supported
  - Mac/Win Monadic Chat Console UI improved
  - Image understanging feature
  - Voice Interpreter app added
  - More responsive text-to-speech in auto-speech mode
  - Language Practice Plus app updated
- [Nov, 2023] Image generator app updated to support dall-e-3.
  - Speech-to-Text voice input is supported for Chrome/Edge/Safari.
  - Natural voice stream playback using OpenAI's text-to-speech API supported.
  - OpenAI's new models supported (0.3.0)
- [Sep, 2023] Stability improvement with several apps modified
- [Jul, 2023] Installers for Mac and Windows released for Monadic Chat (0.2.0).
  - Image generation feature added.
  - The initial version of Monadic Chat (1.0.0) has been released.
  - The original command-line program renamed to [Monadic Chat CLI](https://github.com/yohasebe/monadic-chat-cli) and moved to another repository.
