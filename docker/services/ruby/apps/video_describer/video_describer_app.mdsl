app "VideoDescriberApp" do
  description do
    en <<~TEXT
    Analyze and describe video content. <a href="https://yohasebe.github.io/monadic-chat/#/basic-usage/basic-apps?id=video-describer" target="_blank"><i class="fa-solid fa-circle-info"></i></a>
    TEXT
    
    ja <<~TEXT
    ビデオコンテンツの分析と説明。 <a href="https://yohasebe.github.io/monadic-chat/#/basic-usage/basic-apps?id=video-describer" target="_blank"><i class="fa-solid fa-circle-info"></i></a>
    TEXT
    
    zh <<~TEXT
    分析和描述视频内容。 <a href="https://yohasebe.github.io/monadic-chat/#/basic-usage/basic-apps?id=video-describer" target="_blank"><i class="fa-solid fa-circle-info"></i></a>
    TEXT
    
    ko <<~TEXT
    비디오 콘텐츠 분석 및 설명. <a href="https://yohasebe.github.io/monadic-chat/#/basic-usage/basic-apps?id=video-describer" target="_blank"><i class="fa-solid fa-circle-info"></i></a>
    TEXT
    
    es <<~TEXT
    Analizar y describir contenido de video. <a href="https://yohasebe.github.io/monadic-chat/#/basic-usage/basic-apps?id=video-describer" target="_blank"><i class="fa-solid fa-circle-info"></i></a>
    TEXT
    
    fr <<~TEXT
    Analyser et décrire le contenu vidéo. <a href="https://yohasebe.github.io/monadic-chat/#/basic-usage/basic-apps?id=video-describer" target="_blank"><i class="fa-solid fa-circle-info"></i></a>
    TEXT
    
    de <<~TEXT
    Videoinhalte analysieren und beschreiben. <a href="https://yohasebe.github.io/monadic-chat/#/basic-usage/basic-apps?id=video-describer" target="_blank"><i class="fa-solid fa-circle-info"></i></a>
    TEXT
  end
  
  icon "video"
  
  system_prompt <<~PROMPT
  You are a video describer. You can analyze video content and describe its content.

  First, ask the user to provide the video file and fps (frames per second) to extract frames from the video. Also, let the user know that if the total frames exceed 50, only 50 frames will be extracted proportionally from the video.

  If the user provides a file name, the file should exist in the current directory of the code-running environment. Then, analyze the data using the `analyze_video` function. It takes the filename of the video, the fps, and a query to generate the description of the video content. If the query is omitted, a default text, 'What is happening in the video?' will be used.

  Once you have the results from the `analyze_video` function, provide the user with the original video, a description of the video content, and the transcription of the audio content. The description should be in the following format:

  ### Original Video:

  <video class="to_analyze" src="/data/VIDEO_FILE_NAME" width="100%" controls></video>

  ### Description of the video content:

  DESCRIPTION

  ### Transcription of the audio content:

  TRANSCRIPTION

  If this is a follow-up conversation, you do not need to show the video description again.
  PROMPT
  
  llm do
    provider "openai"
    model ["gpt-5", "gpt-4.1"]
    reasoning_effort "minimal"
  end

  agents do
    speech_to_text model: "gpt-4o-mini-transcribe"
  end

  display_name "Video Describer"

  include_modules "VideoAnalyzeAgent"

  features do
    disabled !CONFIG["OPENAI_API_KEY"]
    temperature 0.0
    presence_penalty 0.2
    easy_submit false
    auto_speech false
    image true
    initiate_from_assistant true
  end

  tools do
    import_shared_tools :content_analysis_openai, visibility: "conditional"
  end
end
