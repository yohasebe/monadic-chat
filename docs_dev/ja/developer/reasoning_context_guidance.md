# 推論コンテキスト設定

このノートは、Monadic ChatがGPT-5推論コンテキストをどのように処理するか、およびアプリMDSLファイルの既存の`context_size`ノブとどのように異なるかを説明します。

## 概念

- **`context_size`（MDSL）**：リクエストを構築する際に含める通常のチャット履歴（user/assistant/toolメッセージ）のターン数を制限します。トークン使用量とノイズを削減するためにセッションバッファーをトリムします。
- **`reasoning_context`（内部）**：Responses APIモードでGPT-5が生成した最新の推論ブロックを保存します。次のリクエストの`reasoning.context`フィールドに最大3セグメントを添付して、モデルが自身の思考を再利用できるようにします。

これら2つのメカニズムは独立して動作します：

| 機能                 | ソース                       | 目的                              |
|----------------------|------------------------------|-----------------------------------|
| `context_size`       | アプリMDSL（`llm`ブロック）   | 以前の会話ターンを制限            |
| `reasoning_context`  | セッションパラメーター（アダプター） | ターン間でGPT-5推論を再利用 |

## デフォルトの動作

- `model`配列で最初に`gpt-5`をリストするアプリは、デフォルトで`reasoning_effort "minimal"`も指定するようになりました。
- OpenAIアダプターは、GPT-5がそれらを返す際にセッションごとに最大`REASONING_CONTEXT_MAX = 3`の推論セグメントを自動的にキャッシュし、そのキャッシュを後続のResponses API呼び出しに再添付します。
- キャッシュは、推論テキストが返されない場合、または新しいセッションが開始される場合にクリアされます。

## MDSLでの公開

`reasoning_context`をMDSLノブとして意図的に公開**しません**。キャッシュはアダプターとResponses APIコントラクトと同期を保つべき内部トランスポート詳細です。MDSLで公開すると、リトライ/キャッシング戦略を進化させることが難しくなり、アプリがフォーマットをオーバーライドしようとすると微妙なバグにつながる可能性があります。

代わりに、アプリ作成者は次のようにすべきです：

1. `reasoning_effort`を明示的に設定（深いchain-of-thoughtが必要でない限り、通常は`"minimal"`）。
2. ユーザー会話の関連部分に基づいて`context_size`を調整。
3. アダプターが推論キャッシュのライフサイクルを自動的に処理することに依存。

## 運用のヒント

- レイテンシをデバッグする際は、`~/monadic/log/extra.log`で`Processing responses API query`エントリと報告された`reasoning_tokens`カウントを検査します。
- 推論ブロックが過度に大きくなる場合、アダプターパラメーターを調整する前にシステムプロンプトを見直して冗長な指示を減らします。
- より長い推論の引き継ぎから利益を得る具体的なユースケースがあり、トレードオフをプロファイリングした場合にのみ、推論キャッシュサイズを増やしてください。
